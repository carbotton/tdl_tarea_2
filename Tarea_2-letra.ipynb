{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2 - Taller de Deep Learning\n",
    "\n",
    "**Fecha de entrega: 16/11/2025**  \n",
    "**Puntaje máximo: 15**\n",
    "\n",
    "## Introducción\n",
    "\n",
    "El objetivo de esta tarea es evaluar su capacidad para aplicar modelos de redes neuronales recurrentes (RNN/LSTM/GRU) en un problema de clasificación de secuencias. En particular, vamos a evaluar la performance de sus modelos en la clasificación de ritmos cardíacos usando datos de electrocardiograma (ECG).\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "El dataset a ser utilizado es el [Heartbeat Dataset](https://www.kaggle.com/datasets/shayanfazeli/heartbeat). Este dataset contiene señales de ECG segmentadas, donde cada segmento corresponde a un latido del corazón. Cada segmento ya está preprocesado y categorizado en una de las siguientes clases:\n",
    "\n",
    "- **N**: Normal (0)\n",
    "- **S**: Arritmia supraventricular (1)\n",
    "- **V**: Arritmia ventricular (2)\n",
    "- **F**: Latido fusionado (3)\n",
    "- **Q**: Latido desconocido (4)\n",
    "\n",
    "Los archivos del dataset que deben utilizar son:\n",
    "\n",
    "- **mitbih_train.csv**: Datos de entrenamiento.\n",
    "- **mitbih_test.csv**: Datos de prueba.\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Tienen total libertad sobre cómo implementar y resolver el problema, así como las técnicas y herramientas que quieran usar. Se recomienda el uso de Google Colab para simplificar el acceso a recursos de GPU, aunque pueden trabajar en sus propias máquinas si lo prefieren. La entrega debe realizarse en formato .ipynb (Jupyter Notebook) **con las celdas ya ejecutadas**.\n",
    "\n",
    "**Restricciones**\n",
    "\n",
    "- No se permite utilizar modelos pre-entrenados; cada modelo debe ser implementado desde cero.\n",
    "- Deben utilizar al menos un modelo basado en RNN (por ejemplo, LSTM o GRU).\n",
    "- Es necesario realizar un **análisis exploratorio de los datos**, que incluya una descripción de las señales ECG, el balanceo de clases y cualquier limpieza o transformación necesaria de los datos.\n",
    "- Las decisiones sobre el preprocesamiento de las señales (como normalización, segmentación, etc.) deben estar fundamentadas en una exploración inicial del dataset y explicadas en el notebook.\n",
    "\n",
    "**Reporte**\n",
    "\n",
    "Se requiere que reporten las siguientes métricas: accuracy, precision, recall y F1-score para la evaluación del modelo. Además, se espera ver una evolución clara del modelo durante el entrenamiento, que incluya logs y gráficas de las métricas tanto para los datos de entrenamiento como de validación.\n",
    "\n",
    "**Evidencia de Experimentos**\n",
    "\n",
    "Deben proporcionar evidencia de la ejecución de experimentos usando [Weights & Biases (wandb)](https://wandb.ai/). Esto incluye:\n",
    "\n",
    "- Registros detallados de los experimentos.\n",
    "- Gráficas y logs de entrenamiento.\n",
    "- Comparaciones entre diferentes configuraciones de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrantes del grupo\n",
    "\n",
    "Natalia Campiglia - 349251\n",
    "\n",
    "Maria Jose Carbajal - 241319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "from torchinfo import summary\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import (\n",
    "    train,\n",
    "    evaluate,\n",
    "    model_classification_report,\n",
    "    show_tensor_image,\n",
    "    show_tensor_images,\n",
    "    plot_training,\n",
    "    EarlyStopping,\n",
    "    print_log,\n",
    "    plot_sweep_metrics_comparison,\n",
    "    download_run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SEED = 34\n",
    "\n",
    "TRAIN_DATA_PATH = \"data/mitbih_train.csv\"\n",
    "TEST_DATA_PATH = \"data/mitbih_test.csv\"\n",
    "\n",
    "TARGET_NAMES = [\n",
    "    \"Normal\",\n",
    "    \"Arritmia supraventricular\",\n",
    "    \"Arritmia ventricular\",\n",
    "    \"Latido fusionado\",\n",
    "    \"Latido desconocido\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos la semilla para que los resultados sean reproducibles\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando cuda\n",
      "Usando 4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# definimos el dispositivo que vamos a usar\n",
    "DEVICE = \"cpu\"  # por defecto, usamos la CPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"  # si hay GPU, usamos la GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"  # si no hay GPU, pero hay MPS, usamos MPS\n",
    "elif torch.xpu.is_available():\n",
    "    DEVICE = \"xpu\"  # si no hay GPU, pero hay XPU, usamos XPU\n",
    "\n",
    "print(f\"Usando {DEVICE}\")\n",
    "\n",
    "NUM_WORKERS = 0 # Win y MacOS pueden tener problemas con múltiples workers\n",
    "if sys.platform == 'linux':\n",
    "    NUM_WORKERS = 4  # numero de workers para cargar los datos (depende de cada caso)\n",
    "\n",
    "print(f\"Usando {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA_PATH, header=None)\n",
    "df_test = pd.read_csv(TEST_DATA_PATH, header=None)\n",
    "\n",
    "# Concatenamos los datos de entrenamiento y test\n",
    "df = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos\n",
    "\n",
    "- Chequear NaNs o esten vacios , que sean negativos\n",
    "- Graficar una señal del dataset para mostrar como se ve\n",
    "- Ver clases balanceo etc\n",
    "- Imprimir minimo, maximo , promedio etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>0.928736</td>\n",
       "      <td>0.871264</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.742529</td>\n",
       "      <td>0.650575</td>\n",
       "      <td>0.535632</td>\n",
       "      <td>0.394253</td>\n",
       "      <td>0.250575</td>\n",
       "      <td>0.140230</td>\n",
       "      <td>0.102299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21888</th>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.692078</td>\n",
       "      <td>0.587444</td>\n",
       "      <td>0.446936</td>\n",
       "      <td>0.318386</td>\n",
       "      <td>0.189836</td>\n",
       "      <td>0.118087</td>\n",
       "      <td>0.077728</td>\n",
       "      <td>0.112108</td>\n",
       "      <td>0.152466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21889</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967359</td>\n",
       "      <td>0.620178</td>\n",
       "      <td>0.347181</td>\n",
       "      <td>0.139466</td>\n",
       "      <td>0.089021</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.100890</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.100890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21890</th>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.567460</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.575397</td>\n",
       "      <td>0.575397</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21891</th>\n",
       "      <td>0.973970</td>\n",
       "      <td>0.913232</td>\n",
       "      <td>0.865510</td>\n",
       "      <td>0.823210</td>\n",
       "      <td>0.746204</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.547722</td>\n",
       "      <td>0.426247</td>\n",
       "      <td>0.325380</td>\n",
       "      <td>0.279826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109446 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1      0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2      1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3      0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4      0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21887  0.928736  0.871264  0.804598  0.742529  0.650575  0.535632  0.394253   \n",
       "21888  0.802691  0.692078  0.587444  0.446936  0.318386  0.189836  0.118087   \n",
       "21889  1.000000  0.967359  0.620178  0.347181  0.139466  0.089021  0.103858   \n",
       "21890  0.984127  0.567460  0.607143  0.583333  0.607143  0.575397  0.575397   \n",
       "21891  0.973970  0.913232  0.865510  0.823210  0.746204  0.642082  0.547722   \n",
       "\n",
       "            7         8         9    ...  178  179  180  181  182  183  184  \\\n",
       "0      0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "21887  0.250575  0.140230  0.102299  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21888  0.077728  0.112108  0.152466  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21889  0.100890  0.106825  0.100890  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21890  0.488095  0.392857  0.238095  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21891  0.426247  0.325380  0.279826  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       185  186  187  \n",
       "0      0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "21887  0.0  0.0  4.0  \n",
       "21888  0.0  0.0  4.0  \n",
       "21889  0.0  0.0  4.0  \n",
       "21890  0.0  0.0  4.0  \n",
       "21891  0.0  0.0  4.0  \n",
       "\n",
       "[109446 rows x 188 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 5 clases y 187 características\n"
     ]
    }
   ],
   "source": [
    "ninputs = df.shape[1] - 1\n",
    "nclasses = df.iloc[:, -1].nunique()\n",
    "print(f\"Existen {nclasses} clases y {ninputs} características\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87554 entries, 0 to 87553\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(188)\n",
      "memory usage: 125.6 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1  0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2  1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3  0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4  0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21892 entries, 0 to 21891\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(188)\n",
      "memory usage: 31.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758264</td>\n",
       "      <td>0.111570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080579</td>\n",
       "      <td>0.078512</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908425</td>\n",
       "      <td>0.783883</td>\n",
       "      <td>0.531136</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.730088</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.399329</td>\n",
       "      <td>0.238255</td>\n",
       "      <td>0.147651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.070470</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.758264  0.111570  0.000000  0.080579  0.078512  0.066116   \n",
       "1  0.908425  0.783883  0.531136  0.362637  0.366300  0.344322  0.333333   \n",
       "2  0.730088  0.212389  0.000000  0.119469  0.101770  0.101770  0.110619   \n",
       "3  1.000000  0.910417  0.681250  0.472917  0.229167  0.068750  0.000000   \n",
       "4  0.570470  0.399329  0.238255  0.147651  0.000000  0.003356  0.040268   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.049587  0.047521  0.035124  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.307692  0.296703  0.300366  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.123894  0.115044  0.132743  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.004167  0.014583  0.054167  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.080537  0.070470  0.090604  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "0.0    90589\n",
      "4.0     8039\n",
      "2.0     7236\n",
      "1.0     2779\n",
      "3.0      803\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Número de muestras por clase'}, xlabel='187'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_count = df.iloc[:, -1].value_counts()\n",
    "print(class_count)\n",
    "\n",
    "class_count.sort_index().plot(kind=\"bar\", title=\"Número de muestras por clase\")\n",
    "\n",
    "## TODO: poner nombre de clases en la grafica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las clases estan desbalanceadas.....\n",
    "\n",
    "COMENTAR EN QUE NOS AFECTA Y DE QUE FORMAS SE PODRIA RESOLVER ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento básico\n",
    "\n",
    "En esta sección definimos preprocesamiento básico.\n",
    "\n",
    "Más adelante hacemos pruebas con y sin balanceo de clases para ver como afecta al resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar datos,  \"z score\" T.Normalize(mean=T_MEAN, std=T_STD),\n",
    "# Ver que hacer con los NaN\n",
    "# pasar a tensor X_train y_train / test \n",
    "# T.ToDtype(torch.float32, scale=True),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, :-1]  # Extraemos las características\n",
    "y_train = df_train.iloc[:, -1]   # Extraemos las etiquetas\n",
    "\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "class MITBIHDataSet(Dataset):\n",
    "    def __init__(self, df_features, df_target, transform=None, target_transform=None):\n",
    "        self.x_df = df_features.values\n",
    "        self.y_df = df_target.values\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.x_df[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y_df[idx], dtype=torch.long)  # la cross-entropy loss necesita que el target sea long\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)        \n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "class ECGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ECG latidos segmentados de longitud fija (187).\n",
    "    Devuelve tensores para RNN con shape [T, 1].\n",
    "    \"\"\"\n",
    "    def _init_(\n",
    "        self,\n",
    "        X: np.ndarray,           # shape [N, 187]\n",
    "        y: np.ndarray,           # shape [N]\n",
    "        transform: Optional[Callable[[np.ndarray], np.ndarray]] = None\n",
    "    ):\n",
    "        assert len(X) == len(y), \"X e y deben tener mismo largo\"\n",
    "        self.X = X\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.transform = transform\n",
    "\n",
    "    def _len_(self) -> int:\n",
    "        return len(self.X)\n",
    "\n",
    "    def _getitem_(self, idx: int) -> Tuple[Tensor, Tensor]:\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        # RNN: [T, 1]\n",
    "        x_t = torch.tensor(x, dtype=torch.float32).unsqueeze(-1)\n",
    "        y_t = torch.tensor(y, dtype=torch.long)\n",
    "        return x_t, y_t\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PASAR A UTILS\n",
    "# Wrapper para aplicar transformaciones\n",
    "class TransformDataset(torch.Tensor):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "        return self.transform(image), label\n",
    "\n",
    "def get_dataloaders(\n",
    "    X_train, y_train, train_transf=[], val_transf=[], batch_size=BATCH_SIZE, num_workers=NUM_WORKERS\n",
    "):\n",
    "    \"\"\"\n",
    "    Función para obtener los dataloaders de entrenamiento, validación y test\n",
    "\n",
    "    Args:\n",
    "    - X_train: features del dataset\n",
    "    - y_train: labels del dataset\n",
    "    - train_transf: transformaciones para el dataset de entrenamiento\n",
    "    - val_transf: transformaciones para el dataset de val\n",
    "    - batch_size: tamaño del batch\n",
    "    - num_workers: número de workers para cargar los datos\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    # usando stratify para mantener distribucion de los datos\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    "    )\n",
    "\n",
    "    # aplicamos las transformaciones\n",
    "    train_dataset = TransformDataset(train_dataset, train_transf)\n",
    "    validation_dataset = TransformDataset(validation_dataset, test_transf)\n",
    "\n",
    "    # creamos los dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        validation_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_transf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m train_loader, val_loader, test_loader = get_dataloaders(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     X_train, y_train, \u001b[43mtrain_transf\u001b[49m, test_transf\n\u001b[32m      3\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'train_transf' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    X_train, y_train, train_transf, test_transf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opcion sin augmentation con class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opcion con augmentation sin class weights\n",
    "random oversampling / undersampling\n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=weights_tensor,\n",
    "    num_samples=len(weights_tensor),  # mismo tamaño que el dataset\n",
    "    replacement=True  # importante, permite repetir ejemplos minoritarios\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opcion con augmentation y con class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver transfer learning entre nuestras pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 1: RNN basica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 2: GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 3: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
